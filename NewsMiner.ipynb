{
 "metadata": {
  "name": "",
  "signature": "sha256:2cbcee7dd5791221a3a65d79419227b655f719250311573f0383a2a8d2130c51"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import nltk\n",
      "import datetime\n",
      "import requests\n",
      "from lxml import html"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Article:\n",
      "    def __init__(self, url, title, text, tags, published_at, **kwargs):\n",
      "        self.url = url\n",
      "        self.title = title   \n",
      "        self.text = text\n",
      "        self.tags = tags\n",
      "        self.published_at = published_at\n",
      "        self.domain = kwargs.get('domain', '')\n",
      "        self.summary = kwargs.get('summary', '')\n",
      "\n",
      "class NewsPageParserBase(object):\n",
      "    def __init__(self):\n",
      "        pass\n",
      "        \n",
      "    def get_article(self, page, url):\n",
      "        tree = self.get_page_tree(page)\n",
      "        title = self.get_title(tree)\n",
      "        text = self.get_article_text(tree)\n",
      "        tags = self.get_tags(tree)\n",
      "        date = self.get_date_published(tree)\n",
      "        summary = self.get_summary(tree)\n",
      "        \n",
      "        article = Article(url, title, text, tags, date, summary = summary)\n",
      "        return article\n",
      "        \n",
      "    def get_page_tree(self, page):\n",
      "        return html.fromstring(page)\n",
      "        \n",
      "    def get_article_text(self, tree):\n",
      "        pass\n",
      "    \n",
      "    def get_title(self, tree):\n",
      "        pass\n",
      "    \n",
      "    def get_tags(self, tree):\n",
      "        pass\n",
      "    \n",
      "    def get_date_published(self, tree):\n",
      "        pass\n",
      "    \n",
      "    def get_summary(self, tree):\n",
      "        pass\n",
      "    \n",
      "class NewsArchivePageParserBase(object):\n",
      "    def __init__(self, base_url):\n",
      "        self.base_url = base_url\n",
      "    \n",
      "    def get_news_urls(self, page):\n",
      "        pass\n",
      "    \n",
      "class NewsClientBase(object):\n",
      "    def __init__(self, base_url, archive_url):\n",
      "        self.base_url = base_url\n",
      "        self.archive_url = archive_url\n",
      "        \n",
      "    def get_article_page(self, url):\n",
      "        response = requests.get(url)\n",
      "        return response.content\n",
      "    \n",
      "    def get_archive_page(self, date):\n",
      "        url = self.get_archive_url(date)\n",
      "        response = requests.get(url)\n",
      "        return response.content\n",
      "            \n",
      "    def get_archive_url(self, date):\n",
      "        pass\n",
      "    \n",
      "class NewsRequestManagerBase(object):\n",
      "    def __init__(self, client, news_page_parser):\n",
      "        self.client = client\n",
      "        self.news_page_parser = news_page_parser"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class PravdaPageParser(NewsPageParserBase):\n",
      "    def __init__(self):\n",
      "        super(PravdaPageParser, self).__init__()   \n",
      "        \n",
      "    def get_article_text(self, tree):\n",
      "        paragraphs = tree.xpath('//div[@class=\"text\"]//p/text()')\n",
      "        article = ' '.join(paragraphs)\n",
      "        return article\n",
      "    \n",
      "    def get_title(self, tree):\n",
      "        title = tree.xpath('//h1[@class=\"title\"]/text()')\n",
      "        return title[0]\n",
      "    \n",
      "    def get_tags(self, tree):\n",
      "        tags = tree.xpath('//p[@class=\"tags\"]//a/text()')\n",
      "        return tags   \n",
      "    \n",
      "    def get_date_published(self, tree):\n",
      "        date_published = tree.xpath('//span[@class=\"dt2\"]/text()')\n",
      "        return date_published[0]\n",
      "    \n",
      "class PravdaArchivePageParser(NewsArchivePageParserBase):\n",
      "    def __init__(self, base_url = 'http://www.pravda.com.ua'):\n",
      "        self._news_relative_urls_regex = r'^\\/news(\\/\\d{1,}){1,}\\/$'\n",
      "        super(self.__class__, self).__init__(base_url)\n",
      "    \n",
      "    def get_news_urls(self, page):\n",
      "        urls = self._get_news_block_urls(page)\n",
      "        news_relative_urls = [url for url in urls if re.match(self._news_relative_urls_regex, url)]\n",
      "        news_urls = [self.base_url + url for url in news_relative_urls]\n",
      "        return news_urls\n",
      "    \n",
      "    def _get_news_block_urls(self, page):\n",
      "        tree = html.fromstring(page)\n",
      "        links = tree.xpath('//dl[@class=\"news4\"]//a/@href')\n",
      "        return list(set(links)) \n",
      "\n",
      "class PravdaClient(NewsClientBase):\n",
      "    def __init__(self, language):\n",
      "        base_url = 'http://www.pravda.com.ua'\n",
      "        archive_url = 'http://www.pravda.com.ua/archives/'\n",
      "        super(self.__class__, self).__init__(base_url, archive_url)\n",
      "\n",
      "        if(language == 'rus'):\n",
      "            self.base_url = self.base_url + '/rus'\n",
      "            \n",
      "    def get_archive_url(self, date):\n",
      "        return self.archive_url + 'date_' + date.strftime(\"%d%m%Y\")\n",
      "       \n",
      "class PravdaRequestManager(NewsRequestManagerBase):\n",
      "    def __init__(self, language):\n",
      "        client = PravdaClient(language=language)\n",
      "        news_page_parser = PravdaPageParser()\n",
      "        super(PravdaRequestManager, self).__init__(client, news_page_parser)\n",
      "        self._archive_page_parser = PravdaArchivePageParser()\n",
      "        \n",
      "    def get_news(self, date, limit = 0):\n",
      "        archive_page = self.client.get_archive_page(date)\n",
      "        urls = self._archive_page_parser.get_news_urls(archive_page)\n",
      "        urls = urls if limit <= 0 else urls[:limit]\n",
      "        pages = [self.client.get_article_page(url) for url in urls]\n",
      "        return [self.news_page_parser.get_article(page, url) for page in pages] "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "manager = PravdaRequestManager(language='rus')\n",
      "news = manager.get_news(datetime.datetime.now())\n",
      "print len(news)\n",
      "print news[0].title"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "22\n",
        "\u041d\u0456\u0447 \u0432 \u0437\u043e\u043d\u0456 \u0410\u0422\u041e - \u043d\u0430\u043f\u0440\u0443\u0436\u0435\u043d\u0430, \u0431\u043e\u0439\u043e\u0432\u0438\u043a\u0438 \u0431'\u044e\u0442\u044c \u0437 \u0432\u0430\u0436\u043a\u043e\u0457 \u0437\u0431\u0440\u043e\u0457 \u0456 \u0442\u0430\u043d\u043a\u0456\u0432 - \u0448\u0442\u0430\u0431\n"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class RussiaTodayNewsPageParser(NewsPageParserBase):\n",
      "    def __init__(self, page):\n",
      "        super(self.__class__, self).__init__(page)   NewsPageParserBase\n",
      "        \n",
      "    def get_article_text(self):\n",
      "        paragraphs = tree.xpath('//div[@itemprop=\"articleBody\"]/p/text()')\n",
      "        article = ' '.join(paragraphs)\n",
      "        return article\n",
      "    \n",
      "    def get_title(self):\n",
      "        title = tree.xpath('//h1[@itemprop=\"name\"]/strong/text()')\n",
      "        return title[0]\n",
      "    \n",
      "    def get_short_summary(self):\n",
      "        description = tree.xpath('//div[@itemprop=\"headline description\"]/p/text()')\n",
      "        return description[0] \n",
      "    \n",
      "    def get_date_published(self):\n",
      "        date_published = tree.xpath('//time[@itemprop=\"datePublished\"]/@datetime')\n",
      "        return date_published\n",
      "        \n",
      "class RussiaTodayArchivePageParser(NewsArchivePageParserBase):\n",
      "    def __init__(self, base_url = 'http://russian.rt.com/' ):\n",
      "        super(self.__class__, self).__init__(base_url)\n",
      "    \n",
      "    def get_news_urls(self, page):\n",
      "        urls = self._get_news_block_urls(page)\n",
      "        news_urls = [self.base_url + url for url in urls]\n",
      "        return news_urls\n",
      "    \n",
      "    def _get_news_block_urls(self, page):\n",
      "        tree = html.fromstring(page)\n",
      "        links = tree.xpath('//section[@id=\"news\"]/article/noindex/a/@href')\n",
      "        return list(set(links)) \n",
      "\n",
      "class RussianTodayClient(NewsClientBase):\n",
      "    def __init__(self, base_url, archive_url):\n",
      "        base_url = 'http://russian.rt.com/' \n",
      "        archive_url = base_url + 'all/'\n",
      "        super(RussianTodayClient, self).__init__(base_url, archive_url)\n",
      "        \n",
      "    def get_archive_url(self, date):\n",
      "        return self.archive_url +  date.strftime(\"%Y/%m/%d\")\n",
      "    \n",
      "class RussiaTodayRequestManager(NewsRequestManagerBase):\n",
      "    def __init__(self, language):\n",
      "        client = RussianTodayClient(l)\n",
      "        super(self.__class__, self).__init__(client)\n",
      "        self._archive_page_parser = RussiaTodayArchivePageParser()\n",
      "        \n",
      "    def get_news(self, date, limit = 0):\n",
      "        def get_articles(url):\n",
      "            parser = RussiaTodayNewsPageParser(self.client.get_article_page(url))\n",
      "            title = parser.get_title()\n",
      "            text = parser.get_article_text()\n",
      "            tags = parser.get_tags()\n",
      "            date = parser.get_date_published()\n",
      "            short_summary = parser.get_short_summary()\n",
      "            \n",
      "            article = Article(url, title, text, tags, date, short_summary)  \n",
      "            return article\n",
      "        \n",
      "        archive_page = self.client.get_archive_page(date)\n",
      "        urls = self._archive_page_parser.get_news_urls(archive_page)\n",
      "        urls = urls if limit <= 0 else urls[:limit]\n",
      "        return map(get_articles, urls)  \n",
      "    \n",
      "# 'http://russian.rt.com/article/99847'\n",
      "# 'http://russian.rt.com/all/2015/6/26'    \n",
      "# 'http://russian.rt.com/'        \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "response = requests.get('http://www.pravda.com.ua/news/2015/06/27/7072614/')\n",
      "tree = html.fromstring(response.content)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "urls = tree.xpath('//span[@class=\"dt2\"]/text()')\n",
      "print urls[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u0421\u0443\u0431\u043e\u0442\u0430, 27 \u0447\u0435\u0440\u0432\u043d\u044f 2015, 07:39\n"
       ]
      }
     ],
     "prompt_number": 57
    }
   ],
   "metadata": {}
  }
 ]
}