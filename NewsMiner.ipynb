{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import datetime\n",
    "import requests\n",
    "from lxml import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Article:\n",
    "    def __init__(self, url, title, text, tags, published_at, **kwargs):\n",
    "        self.url = url\n",
    "        self.title = title   \n",
    "        self.text = text\n",
    "        self.tags = tags\n",
    "        self.published_at = published_at\n",
    "        self.domain = kwargs.get('domain', '')\n",
    "        self.summary = kwargs.get('summary', '')\n",
    "\n",
    "class NewsPageParserBase(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def get_article(self, page, url):\n",
    "        tree = self.get_page_tree(page)\n",
    "        title = self.get_title(tree)\n",
    "        text = self.get_article_text(tree)\n",
    "        tags = self.get_tags(tree)\n",
    "        date = self.get_date_published(tree)\n",
    "        summary = self.get_summary(tree)\n",
    "        \n",
    "        article = Article(url, title, text, tags, date, summary = summary)\n",
    "        return article\n",
    "        \n",
    "    def get_page_tree(self, page):\n",
    "        return html.fromstring(page)\n",
    "        \n",
    "    def get_article_text(self, tree):\n",
    "        pass\n",
    "    \n",
    "    def get_title(self, tree):\n",
    "        pass\n",
    "    \n",
    "    def get_tags(self, tree):\n",
    "        pass\n",
    "    \n",
    "    def get_date_published(self, tree):\n",
    "        pass\n",
    "    \n",
    "    def get_summary(self, tree):\n",
    "        pass\n",
    "    \n",
    "class NewsArchivePageParserBase(object):\n",
    "    def __init__(self, base_url):\n",
    "        self.base_url = base_url\n",
    "    \n",
    "    def get_news_urls(self, page):\n",
    "        pass\n",
    "    \n",
    "class NewsClientBase(object):\n",
    "    def __init__(self, base_url, archive_url):\n",
    "        self.base_url = base_url\n",
    "        self.archive_url = archive_url\n",
    "        \n",
    "    def get_article_page(self, url):\n",
    "        response = requests.get(url)\n",
    "        return response.content\n",
    "    \n",
    "    def get_archive_page(self, date):\n",
    "        url = self.get_archive_url(date)\n",
    "        response = requests.get(url)\n",
    "        return response.content\n",
    "            \n",
    "    def get_archive_url(self, date):\n",
    "        pass\n",
    "    \n",
    "class NewsRequestManagerBase(object):\n",
    "    def __init__(self, client, news_page_parser):\n",
    "        self.client = client\n",
    "        self.news_page_parser = news_page_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PravdaConfig(object):\n",
    "    base_url = 'http://www.pravda.com.ua'\n",
    "    archive_url = 'http://www.pravda.com.ua/archives/'\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_base_url(language='ua'):\n",
    "        if(language == 'rus'):\n",
    "            return PravdaConfig.base_url + '/rus'\n",
    "        \n",
    "        return PravdaConfig.base_url\n",
    "\n",
    "class PravdaNewsPageParser(NewsPageParserBase):\n",
    "    def __init__(self):\n",
    "        super(self.__class__, self).__init__()\n",
    "        \n",
    "    def get_article_text(self, tree):\n",
    "        paragraphs = tree.xpath('//div[@class=\"text\"]//p/text()')\n",
    "        article = ' '.join(paragraphs)\n",
    "        return article\n",
    "    \n",
    "    def get_title(self, tree):\n",
    "        title = tree.xpath('//h1[@class=\"title\"]/text()')\n",
    "        return title[0] if len(title) > 0 else ''\n",
    "    \n",
    "    def get_tags(self, tree):\n",
    "        tags = tree.xpath('//p[@class=\"tags\"]//a/text()')\n",
    "        return tags   \n",
    "    \n",
    "    def get_date_published(self, tree):\n",
    "        date_published = tree.xpath('//span[@class=\"dt2\"]/text()')\n",
    "        return date_published\n",
    "    \n",
    "class PravdaArchivePageParser(NewsArchivePageParserBase):\n",
    "    def __init__(self, language):\n",
    "        self._news_relative_urls_regex = r'^\\/news(\\/\\d{1,}){1,}\\/$'\n",
    "        super(self.__class__, self).__init__(PravdaConfig.get_base_url(language))\n",
    "    \n",
    "    def get_news_urls(self, page):\n",
    "        urls = self._get_news_block_urls(page)\n",
    "        news_relative_urls = [url for url in urls if re.match(self._news_relative_urls_regex, url)]\n",
    "        news_urls = [self.base_url + url for url in news_relative_urls]\n",
    "        return news_urls\n",
    "    \n",
    "    def _get_news_block_urls(self, page):\n",
    "        tree = html.fromstring(page)\n",
    "        links = tree.xpath('//dl[@class=\"news4\"]//a/@href')\n",
    "        return list(set(links)) \n",
    "\n",
    "class PravdaClient(NewsClientBase):\n",
    "    def __init__(self, language):\n",
    "        super(self.__class__, self).__init__(PravdaConfig.get_base_url(language), PravdaConfig.archive_url)\n",
    "            \n",
    "    def get_archive_url(self, date):\n",
    "        return self.archive_url + 'date_' + date.strftime(\"%d%m%Y\")\n",
    "       \n",
    "class PravdaRequestManager(NewsRequestManagerBase):\n",
    "    def __init__(self, language='rus'):\n",
    "        client = PravdaClient(language=language)\n",
    "        news_page_parser = PravdaNewsPageParser()\n",
    "        super(self.__class__, self).__init__(client, news_page_parser)\n",
    "        self._archive_page_parser = PravdaArchivePageParser(language=language)\n",
    "        \n",
    "    def get_news(self, date, limit = 0):\n",
    "        archive_page = self.client.get_archive_page(date)\n",
    "        urls = self._archive_page_parser.get_news_urls(archive_page)\n",
    "        urls = urls if limit <= 0 else urls[:limit]\n",
    "        pages_with_urls = [{'page':self.client.get_article_page(url), 'url':url} for url in urls]\n",
    "        return [self.news_page_parser.get_article(item['page'], item['url']) for item in pages_with_urls] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RussiaTodayNewsPageParser(NewsPageParserBase):\n",
    "    def __init__(self):\n",
    "        super(self.__class__, self).__init__()\n",
    "        \n",
    "    def get_article_text(self, tree):\n",
    "        paragraphs = tree.xpath('//div[@itemprop=\"articleBody\"]/p/text()')\n",
    "        article = ' '.join(paragraphs)\n",
    "        return article\n",
    "    \n",
    "    def get_title(self, tree):\n",
    "        title = tree.xpath('//h1[@itemprop=\"name\"]/strong/text()')\n",
    "        return title[0]\n",
    "    \n",
    "    def get_summary(self, tree):\n",
    "        description = tree.xpath('//div[@itemprop=\"headline description\"]/p/text()')\n",
    "        return description[0] \n",
    "    \n",
    "    def get_date_published(self, tree):\n",
    "        date_published = tree.xpath('//time[@itemprop=\"datePublished\"]/@datetime')\n",
    "        return datetime.datetime.strptime(date_published, \"%Y-%m-%dT%H:%M\")\n",
    "        \n",
    "class RussiaTodayArchivePageParser(NewsArchivePageParserBase):\n",
    "    def __init__(self, base_url = 'http://russian.rt.com/' ):\n",
    "        super(self.__class__, self).__init__(base_url)\n",
    "    \n",
    "    def get_news_urls(self, page):\n",
    "        urls = self._get_news_block_urls(page)\n",
    "        news_urls = [self.base_url + url for url in urls]\n",
    "        return news_urls\n",
    "    \n",
    "    def _get_news_block_urls(self, page):\n",
    "        tree = html.fromstring(page)\n",
    "        links = tree.xpath('//section[@id=\"news\"]/article/noindex/a/@href')\n",
    "        return list(set(links)) \n",
    "\n",
    "class RussianTodayClient(NewsClientBase):\n",
    "    def __init__(self):\n",
    "        base_url = 'http://russian.rt.com/' \n",
    "        archive_url = base_url + 'all/'\n",
    "        super(RussianTodayClient, self).__init__(base_url, archive_url)\n",
    "        \n",
    "    def get_archive_url(self, date):\n",
    "        return self.archive_url +  date.strftime(\"%Y/%m/%d\")\n",
    "    \n",
    "class RussiaTodayRequestManager(NewsRequestManagerBase):\n",
    "    def __init__(self):\n",
    "        client = RussianTodayClient()\n",
    "        news_page_parser = RussiaTodayNewsPageParser()\n",
    "        super(self.__class__, self).__init__(client, news_page_parser)\n",
    "        self._archive_page_parser = RussiaTodayArchivePageParser()\n",
    "        \n",
    "    def get_news(self, date, limit = 0):\n",
    "        archive_page = self.client.get_archive_page(date)\n",
    "        urls = self._archive_page_parser.get_news_urls(archive_page)\n",
    "        urls = urls if limit <= 0 else urls[:limit]\n",
    "        pages = [self.client.get_article_page(url) for url in urls]\n",
    "        return [self.news_page_parser.get_article(page, url) for page in pages] \n",
    "    \n",
    "rt_manager = RussiaTodayRequestManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rt_news = rt_manager.get_news(datetime.datetime.now())\n",
    "# print len(rt_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "июня\n",
      "6\n",
      ", 28 6 2015, 04:42\n",
      ", 28 июня 2015, 04:42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(u'\\u044f\\u043d\\u0432\\u0430\\u0440\\u044f',\n",
       " u'\\u0444\\u0435\\u0432\\u0440\\u0430\\u043b\\u044f',\n",
       " u'\\u043c\\u0430\\u0440\\u0442\\u0430',\n",
       " u'\\u0430\\u043f\\u0440\\u0435\\u043b\\u044f',\n",
       " u'\\u043c\\u0430\\u044f',\n",
       " u'\\u0438\\u044e\\u043d\\u044f',\n",
       " u'\\u0438\\u044e\\u043b\\u044f',\n",
       " u'\\u0430\\u0432\\u0433\\u0443\\u0441\\u0442\\u0430',\n",
       " u'\\u0441\\u0435\\u043d\\u0442\\u044f\\u0431\\u0440\\u044f',\n",
       " u'\\u043e\\u043a\\u0442\\u044f\\u0431\\u0440\\u044f',\n",
       " u'\\u043d\\u043e\\u044f\\u0431\\u0440\\u044f',\n",
       " u'\\u0434\\u0435\\u043a\\u0430\\u0431\\u0440\\u044f')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_published = u'Воскресенье, 28 июня 2015, 04:42'\n",
    "date = date_published.split(', ')\n",
    "date_published = date_published.replace(date[0], '')\n",
    "months = (u'января', u'февраля', u'марта', u'апреля', u'мая', u'июня', u'июля', u'августа', u'сентября', u'октября', u'ноября', u'декабря')\n",
    "month = next(i for i,name in enumerate(months,1) if name in u'мая')\n",
    "date = date_published.split(', ')\n",
    "ru_month =  date[1].split(' ')[1]\n",
    "print ru_month\n",
    "numeric_month = next(i for i,name in enumerate(months,1) if name in ru_month)\n",
    "print numeric_month\n",
    "print date_published.replace(ru_month, str(numeric_month))\n",
    "print date_published\n",
    "\n",
    "months"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
